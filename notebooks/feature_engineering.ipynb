{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T18:41:05.253764Z",
     "start_time": "2025-12-10T18:41:05.061351Z"
    }
   },
   "cell_type": "raw",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import fasttext\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/Users/lailaalmohaymid/PycharmProjects/data_mining/data/raw.csv\")# Word length-frequency distribution\n",
    "def extract_arabic_words(text):\n",
    "    text = str(text)\n",
    "    # Remove non-Arabic characters\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Extract words\n",
    "    return re.findall(r'[\\u0600-\\u06FF]+', text)\n",
    "df[\"words\"] = df[\"text\"].apply(extract_arabic_words)\n",
    "\n",
    "def get_arabic_word_lengths(text):\n",
    "    words = extract_arabic_words(text)\n",
    "    return [len(w) for w in words]\n",
    "\n",
    "def get_word_length_frequency(text):\n",
    "    lengths = get_arabic_word_lengths(text)\n",
    "    if not lengths:\n",
    "        return {}\n",
    "    return dict(Counter(lengths))\n",
    "\n",
    "df[\"word_length_frequency\"] = df[\"text\"].apply(get_word_length_frequency)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "print(df[\"words\"])\n",
    "#Average number of S/P\n",
    "def split_paragraphs(text):\n",
    "    text = str(text).strip()\n",
    "    paragraphs = [p.strip() for p in text.split(r'\\s*\\n\\s*\\n\\s*|\\s*\\r\\n\\s*\\r\\n\\s*') if p.strip()]\n",
    "    return paragraphs if paragraphs else [text] if text else []\n",
    "\n",
    "def split_sentences(text):\n",
    "    text = str(text).strip()\n",
    "    parts = re.split(r'(?<=[\\.\\?\\!\\u061F\\u061B])\\s+', text)\n",
    "    sentences = [s.strip() for s in parts if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "df[\"paragraphs\"] = df[\"text\"].apply(split_paragraphs)\n",
    "df[\"sentences\"] = df[\"text\"].apply(split_sentences)\n",
    "\n",
    "df[\"Total number of sentences\"] = df[\"sentences\"].apply(len)\n",
    "df[\"Total number of paragraphs \"] = df[\"paragraphs\"].apply(len)\n",
    "\n",
    "def compute_avg_S_per_P(row):\n",
    "    S = row[\"Total number of sentences\"]\n",
    "    P = row[\"Total number of paragraphs \"]\n",
    "    return S / P if P > 0 else 0\n",
    "\n",
    "df[\"Average number of S/P\"] = df.apply(compute_avg_S_per_P, axis=1)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    text = \"\" if text is None else str(text).strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "df[\"perplexity\"] = df[\"text\"].apply(calculate_perplexity)\n",
    "\n",
    "\n",
    "embedding_model = fasttext.load_model(\n",
    "    \"/Users/lailaalmohaymid/PycharmProjects/data_mining/models/cc.ar.300.bin\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_corpus_vocab(df: pd.DataFrame, words_col: str = \"words\"):\n",
    "\n",
    "    all_words = []\n",
    "\n",
    "    for row_words in df[words_col]:\n",
    "        if isinstance(row_words, list):\n",
    "            all_words.extend(row_words)\n",
    "\n",
    "    counter = Counter(all_words)\n",
    "    print(f\"Total unique words in corpus: {len(counter)}\")\n",
    "    return counter\n",
    "\n",
    "corpus_counter = build_corpus_vocab(df, words_col=\"words\")\n",
    "corpus_vocab = list(corpus_counter.keys())\n",
    "\n",
    "\n",
    "arabic_pattern = re.compile(r'^[\\u0600-\\u06FF]+$')\n",
    "\n",
    "def is_good_token(w: str) -> bool:\n",
    "\n",
    "    if not isinstance(w, str):\n",
    "        return False\n",
    "    if len(w) < 3:\n",
    "        return False\n",
    "    if not arabic_pattern.match(w):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "filtered_vocab = [w for w in corpus_vocab if is_good_token(w)]\n",
    "print(f\"Filtered vocab size: {len(filtered_vocab)}\")\n",
    "\n",
    "\n",
    "word_norms = [\n",
    "    (w, np.linalg.norm(embedding_model.get_word_vector(w)))\n",
    "    for w in filtered_vocab\n",
    "]\n",
    "\n",
    "top50_words = [\n",
    "    w for w, _ in sorted(word_norms, key=lambda x: x[1], reverse=True)[:50]\n",
    "]\n",
    "\n",
    "top50_set = set(top50_words)\n",
    "\n",
    "print(\"Top 50 words (from filtered corpus, sample):\", top50_words[:20])\n",
    "\n",
    "\n",
    "def count_top_embedding_words(word_list, top50_set=top50_set):\n",
    "\n",
    "    if not isinstance(word_list, list):\n",
    "        return 0\n",
    "\n",
    "    return sum(1 for w in word_list if w in top50_set)\n",
    "\n",
    "\n",
    "def apply_feature_57_num_words_in_top50(\n",
    "    df: pd.DataFrame,\n",
    "    words_col: str = \"words\",\n",
    "    feature_col: str = \"num_words_in_top50_embedding\",\n",
    "    progress_step: int = 300,\n",
    "):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if feature_col not in df.columns:\n",
    "        df[feature_col] = 0\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    print(f\"Total rows: {n}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        row_words = df.at[i, words_col]\n",
    "        df.at[i, feature_col] = count_top_embedding_words(row_words, top50_set)\n",
    "\n",
    "        if (i + 1) % progress_step == 0 or i == n - 1:\n",
    "            print(f\"Processed {i + 1}/{n} rows \")\n",
    "\n",
    "    print(\"\\n(num_words_in_top50_embedding) completed \")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = apply_feature_57_num_words_in_top50(\n",
    "    df,\n",
    "    words_col=\"words\",\n",
    "    feature_col=\"num_words_in_top50_embedding\",\n",
    "    progress_step=300\n",
    ")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def calculate_perplexity_batch(texts, batch_size=16, max_length=256):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        cleaned_batch = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, t in enumerate(batch_texts):\n",
    "            if pd.notna(t) and str(t).strip():\n",
    "                cleaned_batch.append(str(t))\n",
    "                batch_indices.append(idx)\n",
    "\n",
    "        if not cleaned_batch:\n",
    "            results.extend([None] * len(batch_texts))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                cleaned_batch,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=True\n",
    "            )\n",
    "\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_perplexities = []\n",
    "                for j in range(len(cleaned_batch)):\n",
    "                    single_input_ids = input_ids[j:j+1]\n",
    "                    single_attention_mask = attention_mask[j:j+1]\n",
    "\n",
    "                    single_output = model(\n",
    "                        single_input_ids,\n",
    "                        attention_mask=single_attention_mask,\n",
    "                        labels=single_input_ids\n",
    "                    )\n",
    "\n",
    "                    loss = single_output.loss\n",
    "                    perplexity = torch.exp(loss).item()\n",
    "                    batch_perplexities.append(perplexity)\n",
    "\n",
    "                batch_results = [None] * len(batch_texts)\n",
    "                for idx, ppl in zip(batch_indices, batch_perplexities):\n",
    "                    batch_results[idx] = ppl\n",
    "\n",
    "                results.extend(batch_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "            results.extend([None] * len(batch_texts))\n",
    "\n",
    "    return results\n",
    "\n",
    "perplexities = calculate_perplexity_batch(df[\"text\"].tolist(), batch_size=16, max_length=256)\n",
    "df[\"perplexity\"] = perplexities\n",
    "print(df.columns.tolist())\n",
    "print(df[\"perplexity\"].describe())\n",
    "print(f\"Non-null values: {df['perplexity'].notna().sum()} / {len(df)}\")\n",
    "print(df[[\"text\", \"perplexity\"]].head(20))\n",
    "\n",
    "def calculate_average_log_prob_batch(texts, batch_size=16, max_length=256):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        cleaned_batch = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, t in enumerate(batch_texts):\n",
    "            if pd.notna(t) and str(t).strip():\n",
    "                cleaned_batch.append(str(t))\n",
    "                batch_indices.append(idx)\n",
    "\n",
    "        if not cleaned_batch:\n",
    "            results.extend([None] * len(batch_texts))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                cleaned_batch,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=True\n",
    "            )\n",
    "\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_probabilities = []\n",
    "                for j in range(len(cleaned_batch)):\n",
    "                    single_input_ids = input_ids[j:j+1]\n",
    "                    single_attention_mask = attention_mask[j:j+1]\n",
    "\n",
    "                    if single_input_ids.shape[1] <= 1:\n",
    "                        batch_probabilities.append(None)\n",
    "                        continue\n",
    "\n",
    "                    single_output = model(\n",
    "                        single_input_ids,\n",
    "                        attention_mask=single_attention_mask,\n",
    "                        labels=single_input_ids\n",
    "                    )\n",
    "\n",
    "                    average_nll = single_output.loss.item()\n",
    "                    average_log_prob = -average_nll\n",
    "                    average_probability = torch.exp(torch.tensor(average_log_prob)).item()\n",
    "                    batch_probabilities.append(average_probability)\n",
    "\n",
    "                batch_results = [None] * len(batch_texts)\n",
    "                for idx, prob in zip(batch_indices, batch_probabilities):\n",
    "                    batch_results[idx] = prob\n",
    "\n",
    "                results.extend(batch_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "            results.extend([None] * len(batch_texts))\n",
    "\n",
    "    return results\n",
    "\n",
    "probabilities = calculate_average_log_prob_batch(df[\"text\"].tolist(), batch_size=16, max_length=256)\n",
    "df[\"gpt2_output_probability\"] = probabilities"
   ],
   "id": "96d4f2c604ba80ae",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-09T16:48:01.429684Z",
     "start_time": "2025-12-09T16:47:58.921202Z"
    }
   },
   "source": [
    "\n",
    "print(df[\"gpt2_output_probability\"].head(10))\n",
    "\n",
    "print(df[\"gpt2_output_probability\"].describe())\n",
    "\n",
    "print(f\"Non-null values: {df['gpt2_output_probability'].notna().sum()} / {len(df)}\")\n",
    "\n",
    "print(df[[\"text\", \"perplexity\", \"gpt2_output_probability\"]].head(20))\n",
    "\n",
    "\n",
    "nltk.download('stopwords', download_dir='/Users/lailaalmohaymid/nltk_data')\n",
    "\n",
    "#uploading stopword\n",
    "url = \"https://raw.githubusercontent.com/mohataher/arabic-stop-words/master/list.txt\"\n",
    "response = requests.get(url)\n",
    "arabic_stopwords = set(response.text.strip().split('\\n'))\n",
    "\n",
    "arabic_diacritics = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "stemmer = ISRIStemmer()\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    return re.sub(arabic_diacritics, '', text)\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(r'[إأآا]', 'ا', text)\n",
    "    text = re.sub(r'ى', 'ي', text)\n",
    "    text = re.sub(r'ؤ', 'و', text)\n",
    "    text = re.sub(r'ئ', 'ي', text)\n",
    "    text = re.sub(r'ة', 'ه', text)\n",
    "    text = re.sub(r'[^؀-ۿ ]+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = remove_diacritics(text)\n",
    "    text = normalize_arabic(text)\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in arabic_stopwords]\n",
    "    tokens = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"abstract_text_clean\"] = df[\"text\"].apply(preprocess_text)\n",
    "print(f\"Number of stopwords: {len(arabic_stopwords)}\")\n",
    "\n",
    "print(f\"\\n stopwords:\")\n",
    "print(list(arabic_stopwords))\n",
    "\n",
    "sample_text = df[\"text\"].iloc[0]\n",
    "clean_text = df[\"abstract_text_clean\"].iloc[0]\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(\"Original text:\")\n",
    "print(sample_text[:200])\n",
    "print(f\"\\n\")\n",
    "print(\"Cleaned text:\")\n",
    "print(clean_text[:200])\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(\"Statistics:\")\n",
    "print(f\"Average original text length: {df['text'].str.len().mean():.0f} characters\")\n",
    "print(f\"Average cleaned text length: {df['abstract_text_clean'].str.len().mean():.0f} characters\")\n",
    "print(f\"Reduction percentage: {(1 - df['abstract_text_clean'].str.len().mean() / df['text'].str.len().mean()) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nNull values in cleaned text: {df['abstract_text_clean'].isna().sum()}\")\n",
    "print(df['label'])\n",
    "\n",
    "def calculate_avg_word_length(texts):\n",
    "    total_length = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            words = str(text).split()\n",
    "            for word in words:\n",
    "                total_length += len(word)\n",
    "                total_words += 1\n",
    "\n",
    "    return total_length / total_words if total_words > 0 else 0\n",
    "\n",
    "def calculate_avg_sentence_length(texts):\n",
    "    total_words = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            sentences = str(text).split('.')\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.strip()\n",
    "                if sentence:\n",
    "                    words = sentence.split()\n",
    "                    total_words += len(words)\n",
    "                    total_sentences += 1\n",
    "\n",
    "    return total_words / total_sentences if total_sentences > 0 else 0\n",
    "\n",
    "def calculate_type_token_ratio(texts):\n",
    "    all_words = []\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            words = str(text).split()\n",
    "            all_words.extend(words)\n",
    "\n",
    "    if len(all_words) == 0:\n",
    "        return 0\n",
    "\n",
    "    unique_words = set(all_words)\n",
    "    return len(unique_words) / len(all_words)\n",
    "\n",
    "human_texts = df[df['label'] == 'human']['abstract_text_clean']\n",
    "ai_texts = df[df['label'] == 'ai']['abstract_text_clean']\n",
    "\n",
    "human_avg = calculate_avg_word_length(human_texts)\n",
    "ai_avg = calculate_avg_word_length(ai_texts)\n",
    "\n",
    "human_sent_len = calculate_avg_sentence_length(human_texts)\n",
    "ai_sent_len = calculate_avg_sentence_length(ai_texts)\n",
    "\n",
    "human_ttr = calculate_type_token_ratio(human_texts)\n",
    "ai_ttr = calculate_type_token_ratio(ai_texts)\n",
    "\n",
    "print(f\"Human avg word length: {human_avg:.2f}\")\n",
    "print(f\"AI avg word length: {ai_avg:.2f}\")\n",
    "print(f\"\\nHuman avg sentence length: {human_sent_len:.2f} words\")\n",
    "print(f\"AI avg sentence length: {ai_sent_len:.2f} words\")\n",
    "print(f\"\\nHuman Type-Token Ratio: {human_ttr:.4f}\")\n",
    "print(f\"AI Type-Token Ratio: {ai_ttr:.4f}\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Total:\", len(df))\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Validation:\", len(val_df))\n",
    "print(\"Test:\", len(test_df))\n",
    "print(df.columns)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lailaalmohaymid/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:48:15.167716Z",
     "start_time": "2025-12-09T16:48:15.165123Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.columns)",
   "id": "59a263a240407ceb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label', 'words', 'word_length_frequency'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:48:20.490282Z",
     "start_time": "2025-12-09T16:48:20.178801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Average number of S/P\n",
    "def split_paragraphs(text):\n",
    "    text = str(text).strip()\n",
    "    paragraphs = [p.strip() for p in text.split(r'\\s*\\n\\s*\\n\\s*|\\s*\\r\\n\\s*\\r\\n\\s*') if p.strip()]\n",
    "    return paragraphs if paragraphs else [text] if text else []\n",
    "\n",
    "def split_sentences(text):\n",
    "    text = str(text).strip()\n",
    "    parts = re.split(r'(?<=[\\.\\?\\!\\u061F\\u061B])\\s+', text)\n",
    "    sentences = [s.strip() for s in parts if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "df[\"paragraphs\"] = df[\"text\"].apply(split_paragraphs)\n",
    "df[\"sentences\"] = df[\"text\"].apply(split_sentences)\n",
    "\n",
    "df[\"Total number of sentences\"] = df[\"sentences\"].apply(len)\n",
    "df[\"Total number of paragraphs \"] = df[\"paragraphs\"].apply(len)\n",
    "\n",
    "def compute_avg_S_per_P(row):\n",
    "    S = row[\"Total number of sentences\"]\n",
    "    P = row[\"Total number of paragraphs \"]\n",
    "    return S / P if P > 0 else 0\n",
    "\n",
    "df[\"Average number of S/P\"] = df.apply(compute_avg_S_per_P, axis=1)\n"
   ],
   "id": "f9ba8068ef3dfaf9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T21:14:06.935816Z",
     "start_time": "2025-12-09T16:49:25.210120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    text = \"\" if text is None else str(text).strip()\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "df[\"perplexity\"] = df[\"text\"].apply(calculate_perplexity)"
   ],
   "id": "9e6860ec0846812c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 35\u001B[39m\n\u001B[32m     31\u001B[39m         loss = outputs.loss\n\u001B[32m     33\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch.exp(loss).item()\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m df[\u001B[33m\"\u001B[39m\u001B[33mperplexity\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_perplexity\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/pandas/core/series.py:4943\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4808\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4809\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4810\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4815\u001B[39m     **kwargs,\n\u001B[32m   4816\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4817\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4818\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4819\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4934\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4935\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4936\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4937\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4938\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4939\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4940\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4941\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4942\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4943\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1419\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1421\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1422\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1496\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1497\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1498\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1499\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1500\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1501\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1502\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1503\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1504\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1506\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1507\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1508\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/pandas/core/base.py:925\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    922\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    923\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m925\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data_mining/.venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/lib.pyx:2999\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 33\u001B[39m, in \u001B[36mcalculate_perplexity\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m     30\u001B[39m     outputs = model(input_ids, labels=input_ids)\n\u001B[32m     31\u001B[39m     loss = outputs.loss\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:34:31.929677Z",
     "start_time": "2025-12-10T16:30:50.796018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # إضافة هذا السطر\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def calculate_perplexity_batch(texts, batch_size=16, max_length=256):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        cleaned_batch = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, t in enumerate(batch_texts):\n",
    "            if pd.notna(t) and str(t).strip():\n",
    "                cleaned_batch.append(str(t))\n",
    "                batch_indices.append(idx)\n",
    "\n",
    "        if not cleaned_batch:\n",
    "            results.extend([None] * len(batch_texts))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                cleaned_batch,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=True\n",
    "            )\n",
    "\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_perplexities = []\n",
    "                for j in range(len(cleaned_batch)):\n",
    "                    single_input_ids = input_ids[j:j+1]\n",
    "                    single_attention_mask = attention_mask[j:j+1]\n",
    "\n",
    "                    single_output = model(\n",
    "                        single_input_ids,\n",
    "                        attention_mask=single_attention_mask,\n",
    "                        labels=single_input_ids\n",
    "                    )\n",
    "\n",
    "                    loss = single_output.loss\n",
    "                    perplexity = torch.exp(loss).item()\n",
    "                    batch_perplexities.append(perplexity)\n",
    "\n",
    "                batch_results = [None] * len(batch_texts)\n",
    "                for idx, ppl in zip(batch_indices, batch_perplexities):\n",
    "                    batch_results[idx] = ppl\n",
    "\n",
    "                results.extend(batch_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "            results.extend([None] * len(batch_texts))\n",
    "\n",
    "    return results\n",
    "\n",
    "perplexities = calculate_perplexity_batch(df[\"text\"].tolist(), batch_size=16, max_length=256)\n",
    "df[\"perplexity\"] = perplexities"
   ],
   "id": "277df2e62de0ecc8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2283/2283 [1:03:39<00:00,  1.67s/it]   \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T18:07:03.953850Z",
     "start_time": "2025-12-10T17:45:41.564893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_average_log_prob_batch(texts, batch_size=16, max_length=256):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        cleaned_batch = []\n",
    "        batch_indices = []\n",
    "\n",
    "        for idx, t in enumerate(batch_texts):\n",
    "            if pd.notna(t) and str(t).strip():\n",
    "                cleaned_batch.append(str(t))\n",
    "                batch_indices.append(idx)\n",
    "\n",
    "        if not cleaned_batch:\n",
    "            results.extend([None] * len(batch_texts))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                cleaned_batch,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=True\n",
    "            )\n",
    "\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_probabilities = []\n",
    "                for j in range(len(cleaned_batch)):\n",
    "                    single_input_ids = input_ids[j:j+1]\n",
    "                    single_attention_mask = attention_mask[j:j+1]\n",
    "\n",
    "                    if single_input_ids.shape[1] <= 1:\n",
    "                        batch_probabilities.append(None)\n",
    "                        continue\n",
    "\n",
    "                    single_output = model(\n",
    "                        single_input_ids,\n",
    "                        attention_mask=single_attention_mask,\n",
    "                        labels=single_input_ids\n",
    "                    )\n",
    "\n",
    "                    average_nll = single_output.loss.item()\n",
    "                    average_log_prob = -average_nll\n",
    "                    average_probability = torch.exp(torch.tensor(average_log_prob)).item()\n",
    "                    batch_probabilities.append(average_probability)\n",
    "\n",
    "                batch_results = [None] * len(batch_texts)\n",
    "                for idx, prob in zip(batch_indices, batch_probabilities):\n",
    "                    batch_results[idx] = prob\n",
    "\n",
    "                results.extend(batch_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "            results.extend([None] * len(batch_texts))\n",
    "\n",
    "    return results\n",
    "\n",
    "probabilities = calculate_average_log_prob_batch(df[\"text\"].tolist(), batch_size=16, max_length=256)\n",
    "df[\"gpt2_output_probability\"] = probabilities"
   ],
   "id": "d0a1ce1ffe197667",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2283/2283 [21:22<00:00,  1.78it/s]  \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T18:43:56.644836Z",
     "start_time": "2025-12-10T18:43:56.509498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', download_dir='/Users/lailaalmohaymid/nltk_data')"
   ],
   "id": "3fa56f8f062cd046",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1028)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T19:09:31.287016Z",
     "start_time": "2025-12-10T19:09:31.255621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Number of stopwords: {len(arabic_stopwords)}\")\n",
    "\n",
    "print(f\"\\n stopwords:\")\n",
    "print(list(arabic_stopwords))\n",
    "\n",
    "sample_text = df[\"text\"].iloc[0]\n",
    "clean_text = df[\"abstract_text_clean\"].iloc[0]\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(\"Original text:\")\n",
    "print(sample_text[:200])\n",
    "print(f\"\\n\")\n",
    "print(\"Cleaned text:\")\n",
    "print(clean_text[:200])\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(\"Statistics:\")\n",
    "print(f\"Average original text length: {df['text'].str.len().mean():.0f} characters\")\n",
    "print(f\"Average cleaned text length: {df['abstract_text_clean'].str.len().mean():.0f} characters\")\n",
    "print(f\"Reduction percentage: {(1 - df['abstract_text_clean'].str.len().mean() / df['text'].str.len().mean()) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nNull values in cleaned text: {df['abstract_text_clean'].isna().sum()}\")"
   ],
   "id": "18aa407b0b06dccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 799\n",
      "\n",
      " stopwords:\n",
      "['ألا', 'خمسون', 'لهم', 'ليت', 'نحن', 'شين', 'أفريل', 'ذهب', 'واكد', 'أربعمئة', 'ضمن', 'لديه', 'أرى', 'أوشك', 'سبحان', 'خ', 'نفسها', 'قاطبة', 'كلَّا', 'نوفمبر', 'يمين', 'تسعين', 'فرادى', 'ماانفك', 'ذات', 'مذ', 'ثمان', 'وهذا', 'اى', 'تفعلين', 'أطعم', 'تم', 'دواليك', 'اربعين', 'اجل', 'يوم', 'ينبغي', 'لمّا', 'أصبح', 'هنا', 'مئتان', 'كانت', 'هى', 'واحد', 'اثر', 'إما', 'أنّى', 'اكد', 'عدة', 'سوى', 'ثمانون', 'إذ', 'بلى', 'وهي', 'ثلاثة', 'ث', 'لكنه', 'ص', 'هيا', 'الألاء', 'عدَّ', 'لام', 'ا?', 'فاء', 'زاي', 'لو', 'بات', 'أنتن', 'تفعلون', 'أعلم', 'ئ', 'كاد', 'ثمّ', 'آناء', 'فيفري', 'اذا', 'كان', 'ين', 'الاولى', 'أين', 'ه', 'ثمّة', 'الذى', 'ثلاث', 'سبعة', 'سبعمئة', 'قد', 'قوة', 'إذما', 'انبرى', 'حتى', 'إياكم', 'كلّما', 'س', 'ساء', 'لدى', 'أل', 'الذي', 'هي', 'أبو', 'التي', 'أربعمائة', 'أمامكَ', 'أيّان', 'هَاتانِ', 'تعلَّم', 'نبَّا', 'وفي', 'انه', 'بغتة', 'ك', 'مثل', 'عين', 'رابع', 'كثيرا', 'الف', 'نفسي', 'وبين', 'آمينَ', 'م', 'امسى', 'حاي', 'حَذارِ', 'بيد', 'لماذا', 'ثلاثمئة', 'ب', 'اصبح', 'أمامك', 'مرّة', 'ؤ', 'عليها', 'تسعون', 'من', 'أقبل', 'فيه', 'أى', 'ثانية', 'حمٌ', 'آهاً', 'صباحا', 'إليكنّ', 'بدلا', 'أربعاء', 'تحوّل', 'احد', 'ماي', 'واوضح', 'أجمع', 'ومن', 'صراحة', 'كلم', 'إلي', 'وُشْكَانَ', 'خميس', 'كذا', 'هناك', 'يلي', 'سبت', 'أضحى', 'إذن', 'جدا', 'أسكن', 'أي', 'ومع', 'عشرة', 'خاء', 'كى', 'صاد', 'عاشر', 'رُبَّ', 'حبيب', 'ط', 'هَذا', 'ثمنمئة', 'آب', 'رويدك', 'كسا', 'آ', 'أكثر', 'بإن', 'عن', 'أيّ', 'منذ', 'إليكم', 'يورو', 'هن', 'أحد', 'نَخْ', 'أجل', 'أمسى', 'لعل', 'هَذَيْنِ', 'صدقا', 'فهي', 'اثني', 'المقبل', 'لوما', 'ليرة', 'شتانَ', 'كلتا', 'جعل', 'كانون', 'أن', 'شمال', 'وله', 'يفعلان', 'ف', 'تسعمائة', 'دال', 'زود', 'كأيّ', 'ما أفعله', 'فما', 'اللتين', 'أما', 'معه', 'ستكون', 'مليار', 'ثالث', 'سبعين', 'ستمائة', 'برس', 'سنوات', 'هَاتَيْنِ', 'عنه', 'أمّا', 'اعلنت', 'غالبا', 'لدن', 'وا', 'عشرون', 'ثم', 'حاشا', 'هَذِه', 'هَاتِي', 'كما', 'اطار', 'وإن', 'أنها', 'بَسْ', 'مارس', 'وهى', 'سحقا', 'دينار', 'يفعلون', 'جويلية', 'شيكل', 'بان', 'بعض', 'تخذ', 'كلا', 'واضافت', '،', 'و6', 'ايام', 'كم', 'اما', 'ريث', 'ت', 'زيارة', 'ضد', 'به', 'إياهما', 'فقط', 'سابع', 'أولاء', 'أخذ', 'الي', 'طاء', 'كل', 'خلا', 'تاسع', 'معاذ', 'تبدّل', 'أربع', 'إياه', 'الان', 'ظل', 'هلم', 'صار', 'كيت', 'وقد', 'وقالت', 'كذلك', 'تَيْنِ', 'مليم', 'عامة', 'نفسك', 'إليكما', 'حيَّ', 'مازال', 'مكانَك', 'وقال', 'ظاء', 'سبتمبر', 'ضحوة', 'عَدَسْ', 'حادي', 'في', 'مه', 'الحالي', 'حقا', 'سنتيم', 'طرا', 'استحال', 'ياء', 'إحدى', 'ز', 'شَتَّانَ', 'باء', 'فبراير', 'اربعة', 'لولا', 'ظنَّ', 'يونيو', 'ة', 'ذو', 'إذاً', 'أنتِ', 'حدَث', 'ستة', 'مكانكما', 'ميم', 'ثمانين', 'تكون', 'مما', 'حيث', 'شرع', 'إذا', 'رزق', 'لبيك', 'كاف', 'حاليا', 'غادر', 'لاسيما', 'هللة', 'هَؤلاء', 'اللذين', 'حار', 'أنفسنا', 'صبر', 'ليسب', 'متى', 'هكذا', 'أنا', 'غ', 'اثنان', 'حرى', 'طاق', 'فهى', 'ديك', 'تجاه', 'رأى', 'له', 'ايضا', 'شخصا', 'عدد', 'التى', 'خمسمئة', 'الذين', 'أغسطس', 'مقابل', 'خامس', 'فى', 'حمدا', 'لازال', 'ثاني', 'اربعون', 'ر', 'ما برح', 'ريال', 'مساء', 'حبذا', 'ألفى', 'عاد', 'والذي', 'هبّ', 'عندما', 'الذاتي', 'دولار', 'ولا', 'أصلا', 'أربعة', 'صهٍ', 'عام', 'ذال', 'سرا', 'خمسين', 'اثنا', 'قال', 'اي', 'إى', 'حين', 'غين', 'ثلاثاء', 'وجود', 'إلَيْكَ', 'أنتم', 'أبٌ', 'سقى', 'الثانية', 'لا', 'كن', 'يوليو', 'الآن', 'لأن', 'وأن', 'لايزال', 'انقلب', 'ذاك', 'صهْ', 'االتى', 'مايو', 'أنت', 'إيانا', 'ماذا', 'أنتما', 'راء', 'فو', 'تارة', 'ثامن', 'او', 'عجبا', 'سمعا', 'الاول', 'ما', 'عسى', 'أخو', 'قرش', 'أ', 'مائة', 'نفس', 'بشكل', 'يمكن', 'رجع', 'خال', 'بن', 'سوف', 'وكل', 'عنها', 'إنه', 'هما', 'آض', 'ستون', 'علًّ', 'أبريل', 'وثي', 'بسّ', 'علم', 'وهب', 'بعيدا', 'ذ', 'و', 'حسب', 'يناير', 'هَيْهات', 'تفعلان', 'ظلّ', 'إياي', 'جنيه', 'االا', 'قام', 'نعم', 'أخٌ', 'ولن', 'آخر', 'زعم', 'آه', 'أو', 'ل', 'بطآن', 'ثمانمئة', 'إمّا', 'إن', 'وكانت', 'تلك', 'هل', 'كيف', 'بخٍ', 'بَلْهَ', 'قاف', 'ابين', 'صفر', 'ج', 'معها', 'عيانا', 'طفق', 'لكنَّ', 'أبدا', 'اضحى', 'عشر', 'أوت', 'مئة', 'اخلولق', 'إيهٍ', 'أيار', 'دونك', 'كيفما', 'تانِك', 'سبعون', 'شبه', 'جير', 'بها', 'لما', 'ثان', 'انت', 'طَق', 'أخبر', 'ي', 'بهذا', 'مادام', 'اليه', 'أولالك', 'سين', 'ض', 'خبَّر', 'مع', 'خلف', 'علي', 'آهِ', 'سادس', 'امس', 'لكن', 'لقاء', 'اخرى', 'أيضا', 'نيسان', 'ألف', 'ها', 'هذه', 'ذِه', 'ثلاثين', 'ذانك', 'فكان', 'كأنّ', 'إلّا', 'الألى', 'ق', 'تِي', 'هلّا', 'شباط', 'قلما', 'ايار', 'ذينك', 'بأن', 'اول', 'تسعة', 'أول', 'ذيت', 'إياهم', 'الاخيرة', 'ذلك', 'تينك', 'نحو', \"تحت'\", 'ذانِ', 'واو', 'اتخذ', 'همزة', 'فأن', 'خاصة', 'عوض', 'تلقاء', 'انها', 'أنفسكم', 'بينما', 'وجد', 'وأبو', 'كأن', 'غداة', 'عليه', 'مكانكنّ', 'آل', 'خلال', 'ء', 'فعل', 'للامم', 'بسبب', 'ترك', 'مايزال', 'إياك', 'جيم', 'تعسا', 'هَذِي', 'يجري', 'ستمئة', 'طالما', 'نون', 'كأيّن', 'ولم', 'أفٍّ', 'اللواتي', 'مكانكم', 'إليكَ', 'هَجْ', 'أكتوبر', 'دون', 'فوق', 'اليوم', 'فهو', 'صباح', 'اف', 'وَيْ', 'فيها', 'فلان', 'اليها', 'إضافي', 'جلل', 'لنا', 'ورد', 'غير', 'أنفسهم', 'نَّ', 'على', 'امام', 'اللاتي', 'اللذان', 'ثمَّ', 'ذَيْنِ', 'إياكن', 'حجا', 'لذلك', 'اكثر', 'درى', 'لي', 'مابرح', 'باسم', 'خمسة', 'تِه', 'حمو', 'عاما', 'تسعمئة', 'ن', 'بد', 'ديسمبر', 'ا', 'وكان', 'مافتئ', 'أنه', 'وعلى', 'جميع', 'بعد', 'هنالك', 'ارتدّ', 'قطّ', 'واضاف', 'هَذانِ', 'آهٍ', 'قليل', 'لات', 'حول', 'لك', 'لم', 'ذِي', 'مهما', 'الى', 'هذا', 'وما', 'فإن', 'لعلَّ', 'ع', 'عل', 'ستين', 'منه', 'إنها', 'سبع', 'فقد', 'الماضي', 'د', 'هؤلاء', 'إزاء', 'أنشأ', 'أمد', 'وان', 'أعطى', 'بعدا', 'لها', 'أوّهْ', 'هاكَ', 'ولايزال', 'بؤسا', 'يوان', 'حزيران', 'عند', 'مليون', 'درهم', 'ح', 'عليك', 'جوان', 'هَاتِه', 'الوقت', 'بين', 'نهاية', 'نيف', 'مرة', 'ثلاثون', 'ذا', 'تحت', 'بل', 'قبل', 'هيّا', 'جمعة', 'هيهات', 'إياكما', 'ليس', 'آذار', 'ظ', 'حاء', 'لا سيما', 'فضلا', 'ست', 'إنَّ', 'أفعل به', 'معظم', 'ضاد', 'ثلاثمائة', 'أُفٍّ', 'سنة', 'ثاء', 'نفسه', 'أنًّ', 'إياها', 'ما انفك', 'أولئك', 'اعادة', 'خمسمائة', 'جانفي', 'عدا', 'منها', 'أنبأ', 'خلافا', 'ى', 'ّأيّان', 'وقف', 'كِخ', 'ثماني', 'لعمر', 'لدي', 'حوالى', 'إلى', 'فانه', 'تسع', 'لن', 'الثاني', 'آنفا', 'وراءَك', 'ولكن', 'فلس', 'والتي', 'عدم', 'لهذا', 'يكون', 'اللتيا', 'وهو', 'أيا', 'خمس', 'تموز', 'راح', 'خارج', 'الا', 'حيثما', 'ثمانية', 'أيلول', 'أمام', 'علق', 'ءَ', 'سرعان', 'لوكالة', 'أم', 'صبرا', 'اللتان', 'أمس', 'إياهن', 'السابق', 'فان', 'إلا', 'هو', 'سبعمائة', 'بئس', 'عشرين', 'تانِ', 'تاء', 'هم', 'واهاً', 'ش', 'اثنين', 'ان', 'ا?ى', 'كرب', 'نا', 'بضع', 'تشرين', 'غدا', 'هاء', 'ابتدأ', 'ـ', 'أهلا', 'وليس']\n",
      "\n",
      "\n",
      "Original text:\n",
      "كثيرا ما ارتبطت المصادر التاريخية في الأندلس خاصة منها كتب التراجم والفهرسات والبرامج وغيرها بدراسة حياة العلماء والرواة والقضاة والساسة ؛ وقد تطورت هذه المادة حتى ترك لنا المؤلفون الأندلسيون سلسلة مت\n",
      "\n",
      "\n",
      "Cleaned text:\n",
      "ربط صدر ارخ دلس خصه كتب رجم هرس رمج وغر درس حيه علماء روه قضه سسه ؛ تطر اده حتي ولف دلس لسل واصل حلق كتب ـرجم صله لبن شكوال وصل صله لبن زبير، كمل كتب صله لبن بر، ذيل كمل كتب وصل صله لبن عبد ملك ركش ضف\n",
      "\n",
      "\n",
      "Statistics:\n",
      "Average original text length: 662 characters\n",
      "Average cleaned text length: 337 characters\n",
      "Reduction percentage: 49.1%\n",
      "\n",
      "Null values in cleaned text: 0\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T19:30:45.267559Z",
     "start_time": "2025-12-10T19:30:44.551928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calculate_avg_word_length(texts):\n",
    "    total_length = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            words = str(text).split()\n",
    "            for word in words:\n",
    "                total_length += len(word)\n",
    "                total_words += 1\n",
    "\n",
    "    return total_length / total_words if total_words > 0 else 0\n",
    "\n",
    "def calculate_avg_sentence_length(texts):\n",
    "    total_words = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            sentences = str(text).split('.')\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence.strip()\n",
    "                if sentence:\n",
    "                    words = sentence.split()\n",
    "                    total_words += len(words)\n",
    "                    total_sentences += 1\n",
    "\n",
    "    return total_words / total_sentences if total_sentences > 0 else 0\n",
    "\n",
    "def calculate_type_token_ratio(texts):\n",
    "    all_words = []\n",
    "\n",
    "    for text in texts:\n",
    "        if pd.notna(text) and str(text).strip():\n",
    "            words = str(text).split()\n",
    "            all_words.extend(words)\n",
    "\n",
    "    if len(all_words) == 0:\n",
    "        return 0\n",
    "\n",
    "    unique_words = set(all_words)\n",
    "    return len(unique_words) / len(all_words)\n",
    "\n",
    "human_texts = df[df['label'] == 'human']['abstract_text_clean']\n",
    "ai_texts = df[df['label'] == 'ai']['abstract_text_clean']\n",
    "\n",
    "human_avg = calculate_avg_word_length(human_texts)\n",
    "ai_avg = calculate_avg_word_length(ai_texts)\n",
    "\n",
    "human_sent_len = calculate_avg_sentence_length(human_texts)\n",
    "ai_sent_len = calculate_avg_sentence_length(ai_texts)\n",
    "\n",
    "human_ttr = calculate_type_token_ratio(human_texts)\n",
    "ai_ttr = calculate_type_token_ratio(ai_texts)\n",
    "\n",
    "print(f\"Human avg word length: {human_avg:.2f}\")\n",
    "print(f\"AI avg word length: {ai_avg:.2f}\")\n",
    "print(f\"\\nHuman avg sentence length: {human_sent_len:.2f} words\")\n",
    "print(f\"AI avg sentence length: {ai_sent_len:.2f} words\")\n",
    "print(f\"\\nHuman Type-Token Ratio: {human_ttr:.4f}\")\n",
    "print(f\"AI Type-Token Ratio: {ai_ttr:.4f}\")"
   ],
   "id": "345dcd305911965e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human avg word length: 3.35\n",
      "AI avg word length: 3.32\n",
      "\n",
      "Human avg sentence length: 87.24 words\n",
      "AI avg sentence length: 77.45 words\n",
      "\n",
      "Human Type-Token Ratio: 0.0610\n",
      "AI Type-Token Ratio: 0.0082\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T19:34:25.631632Z",
     "start_time": "2025-12-10T19:34:25.579940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Total:\", len(df))\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Validation:\", len(val_df))\n",
    "print(\"Test:\", len(test_df))"
   ],
   "id": "3ac6abfa1e8fec09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 36525\n",
      "Train: 25567\n",
      "Validation: 5479\n",
      "Test: 5479\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16426418a11cfc18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
